{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "AI - Assignment 4 - Mingjie Zeng.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Assignment #4\n",
        "#### Name: Mingjie Zeng\n",
        "#### ID: 671222265\n",
        "#### Email: mzeng2@wpi.edu"
      ],
      "metadata": {
        "id": "fszww7t8JIlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the link to the colab project:\n",
        "\n",
        "https://colab.research.google.com/drive/1nHtuV_kXbc5GxluJqHISUWPGtBv1MTiw?usp=sharing"
      ],
      "metadata": {
        "id": "MirMO49OAzDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "QkUZxGRyJ_Vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data pre-processing**"
      ],
      "metadata": {
        "id": "yFb2XlSSK9Mo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read data\n",
        "data_body = pd.read_csv(\"./emails/dbworld_bodies_stemmed.csv\")\n",
        "data_subject = pd.read_csv(\"./emails/dbworld_subjects_stemmed.csv\")\n",
        "\n",
        "print(data_body.shape)\n",
        "print(data_body.head())\n",
        "print(data_subject.shape)\n",
        "print(data_subject.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 3723)\n",
            "   id  000euro  05102011  10th  11th  12noon  ...  özsu  û37  û42  û46  û56  CLASS\n",
            "0   1        0         0     0     0       0  ...     0    0    0    0    0      0\n",
            "1   2        0         0     0     0       0  ...     0    0    0    0    0      0\n",
            "2   3        0         0     0     0       0  ...     0    0    0    0    0      0\n",
            "3   4        0         0     0     0       0  ...     0    0    0    0    0      0\n",
            "4   5        0         0     0     0       0  ...     0    0    0    0    0      0\n",
            "\n",
            "[5 rows x 3723 columns]\n",
            "(64, 231)\n",
            "   id  10th  13th  1st  2nd  ...  wireless  workflow  workshop  zurich  CLASS\n",
            "0   1     0     0    0    0  ...         0         0         0       0      0\n",
            "1   2     0     0    0    0  ...         0         0         0       1      0\n",
            "2   3     0     0    0    0  ...         0         0         0       0      0\n",
            "3   4     0     0    0    0  ...         0         0         0       0      0\n",
            "4   5     0     0    0    0  ...         0         0         0       0      0\n",
            "\n",
            "[5 rows x 231 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haguAAH-K80b",
        "outputId": "7a7e63e6-3838-4105-f1e1-5ae51554ec5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# delete the \"id\" column\n",
        "data_body.drop(labels='id',axis=1,inplace = True)\n",
        "data_subject.drop(labels='id',axis=1,inplace = True)\n",
        "\n",
        "print(data_body.shape)\n",
        "print(data_body.head())\n",
        "print(data_subject.shape)\n",
        "print(data_subject.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 3722)\n",
            "   000euro  05102011  10th  11th  12noon  12th  ...  özsu  û37  û42  û46  û56  CLASS\n",
            "0        0         0     0     0       0     0  ...     0    0    0    0    0      0\n",
            "1        0         0     0     0       0     0  ...     0    0    0    0    0      0\n",
            "2        0         0     0     0       0     0  ...     0    0    0    0    0      0\n",
            "3        0         0     0     0       0     0  ...     0    0    0    0    0      0\n",
            "4        0         0     0     0       0     0  ...     0    0    0    0    0      0\n",
            "\n",
            "[5 rows x 3722 columns]\n",
            "(64, 230)\n",
            "   10th  13th  1st  2nd  31st  ...  wireless  workflow  workshop  zurich  CLASS\n",
            "0     0     0    0    0     0  ...         0         0         0       0      0\n",
            "1     0     0    0    0     0  ...         0         0         0       1      0\n",
            "2     0     0    0    0     0  ...         0         0         0       0      0\n",
            "3     0     0    0    0     0  ...         0         0         0       0      0\n",
            "4     0     0    0    0     0  ...         0         0         0       0      0\n",
            "\n",
            "[5 rows x 230 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaMeIr5FMaNT",
        "outputId": "06c9d04c-4e0b-40a5-b68c-9243cf14b63c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# train and test dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data_body\n",
        "data_b = data_body.copy()\n",
        "y_b = data_body['CLASS'].values\n",
        "data_b.drop(['CLASS'], axis=1, inplace=True)\n",
        "\n",
        "print(data_b.shape)\n",
        "print(y_b)\n",
        "\n",
        "# data_subject\n",
        "data_s = data_subject.copy()\n",
        "y_s = data_subject['CLASS'].values\n",
        "data_s.drop(['CLASS'], axis=1, inplace=True)\n",
        "\n",
        "print(data_s.shape)\n",
        "print(y_s)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 3721)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0]\n",
            "(64, 229)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdiece9ZOlM9",
        "outputId": "5e2ce935-9a51-47cb-e690-d498782b70ae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# split the dataset\n",
        "\n",
        "# data_body\n",
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(data_b, y_b, test_size=0.2, stratify=y_b)\n",
        "\n",
        "# data_body\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(data_s, y_s, test_size=0.2, stratify=y_s)\n",
        "\n",
        "print(\"Train data:\", X_train_b.shape, y_train_b.shape)\n",
        "print(\"Test data:\", X_test_b.shape, y_test_b.shape)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: (51, 3721) (51,)\n",
            "Test data: (13, 3721) (13,)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSx5rBN9PvGY",
        "outputId": "f068df72-b075-4517-f456-454fd87bc3dc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "print(type(X_train_b))\n",
        "print(type(y_train_b))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AYKEPmaWZ13",
        "outputId": "26ccdd8a-c0b6-4a84-c83e-c15afd184230"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. You should implement from scratch a Naïve Bayes classifier (using the spam filter example discussed in class).Also implement Laplacian smoothing to handle words not in the dictionary. (60 points)**\n"
      ],
      "metadata": {
        "id": "bG0KuKQVKG59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "source": [
        "import numpy as np\n",
        "class NaiveBayesClassifier:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def fit(self,data,y):\n",
        "    # turn data from pd to array\n",
        "    X = np.array(data)\n",
        "    X = X[:, 0:225]\n",
        "    # merged array\n",
        "    self.Xy = np.c_[X, y]\n",
        "    # all class\n",
        "    self.y_label = np.unique(self.Xy[:, -1])\n",
        "    print(\"labels:\", self.y_label)\n",
        "\n",
        "  def predict(self,data_df):\n",
        "    data = np.array(data_df)\n",
        "    data = data[:, 0:225]\n",
        "    # predicted label\n",
        "    pred = []\n",
        "    # predict every input email\n",
        "    for i in range(len(data)):\n",
        "      result = self.predict_one(data[i])\n",
        "      pred.append(result)\n",
        "    return np.array(pred)\n",
        "  \n",
        "  def predict_one(self, data_one):\n",
        "    # prior probability\n",
        "    prob = []\n",
        "    # prior probability for each label\n",
        "    for i in range(len(self.y_label)):\n",
        "      # number of data with label i\n",
        "      num_y_i = np.sum(self.Xy[:, -1] == self.y_label[i])\n",
        "      # laplacian smoothing\n",
        "      result = (num_y_i + 1) / (len(self.Xy) + len(self.y_label))\n",
        "      prob.append(float(result))\n",
        "    #print(\"prior probability:\", prob)\n",
        "\n",
        "    # conditional probability\n",
        "    for i in range(len(data_one)):\n",
        "      # word vector for every word in the email\n",
        "      value = data_one[i]\n",
        "      # conditional probability for each label\n",
        "      for j in range(len(self.y_label)):\n",
        "        # data with label j\n",
        "        data_y_j = self.Xy[self.Xy[:,-1] == self.y_label[j]]\n",
        "        # number of words with value i\n",
        "        num_value_j = np.sum([data_y_j[:, i] == value])\n",
        "        # laplacian smoothing\n",
        "        result = (num_value_j + 1) / (len(data_y_j) + len(np.unique(self.Xy[:, i]))) \n",
        "        #result *= 10\n",
        "        prob[j] *= float(result)\n",
        "    print(\"conditional probability:\", prob)\n",
        "    \n",
        "    return self.y_label[np.argmax(np.array(prob))]\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "_4rmobi0InRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Using the implemented algorithm, train and test the model for each dataset.**\n",
        "**Use 80% of each class data to train your classifier and the remaining 20% to test it. Which dataset provides better classification i.e. email body or email subject? (30 points)**\n",
        "**$$f - measure= \\frac{2 \\times Pre\\times Rec}{ Pre + Rec}$$**\n",
        "**where** \n",
        "**$$Pre=\\frac{ TP}{TP + FP}$$; \n",
        "$$Rec= \\frac{TP}{TP + FN}$$ ;\n",
        "and TP is the number of true positives (class 1 members predicted as class 1), TN is the number of true negatives (class 2 members predicted as class 2),**\n",
        "**FP is the number of false positives (class 2 members predicted as class 1),**\n",
        "**and FN is the number of false negatives (class 1 members predicted as class 2).**"
      ],
      "metadata": {
        "id": "dBCTdPKsmGXJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "source": [
        "# data_body\n",
        "clf_body = NaiveBayesClassifier()\n",
        "clf_body.fit(X_train_b, y_train_b)\n",
        "pred_body = clf_body.predict(X_test_b)\n",
        "\n",
        "# data_subject\n",
        "clf_subject = NaiveBayesClassifier()\n",
        "clf_subject.fit(X_train_s, y_train_s)\n",
        "pred_subject = clf_subject.predict(X_test_s)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels: [0 1]\n",
            "conditional probability: [2.8201819304000913e-19, 1.8708739834740405e-23]\n",
            "conditional probability: [2.1137702445630414e-13, 4.02916757882641e-15]\n",
            "conditional probability: [7.160103124256676e-10, 2.320800525404012e-12]\n",
            "conditional probability: [5.89453914040532e-15, 6.515003271548286e-18]\n",
            "conditional probability: [1.2888185623662022e-07, 1.3587232166910777e-10]\n",
            "conditional probability: [8.215398438320387e-14, 1.21402260036953e-18]\n",
            "conditional probability: [1.6419940164721106e-18, 2.5415745698525594e-19]\n",
            "conditional probability: [6.789361268737836e-16, 1.8804962320009646e-17]\n",
            "conditional probability: [5.298164130561774e-10, 3.771127348957554e-13]\n",
            "conditional probability: [1.489527528653794e-29, 2.4568009067595123e-30]\n",
            "conditional probability: [2.1831916647240826e-30, 2.285094821407966e-28]\n",
            "conditional probability: [5.692042184215624e-27, 1.4404272034379522e-19]\n",
            "conditional probability: [3.8117718239531125e-18, 9.936196878024423e-21]\n",
            "labels: [0 1]\n",
            "conditional probability: [1.8602580905379507e-17, 3.8818583749311834e-16]\n",
            "conditional probability: [6.562990543417893e-15, 1.0713929114810064e-13]\n",
            "conditional probability: [1.8387689022507064e-15, 6.643317498041125e-17]\n",
            "conditional probability: [4.789239737222935e-09, 9.183722109292047e-13]\n",
            "conditional probability: [7.069278385338699e-12, 1.2523257421761872e-13]\n",
            "conditional probability: [2.132971926610818e-13, 3.826550878871688e-14]\n",
            "conditional probability: [3.0157348021660685e-19, 3.7746122147960927e-19]\n",
            "conditional probability: [8.070714961845807e-16, 2.96478632143984e-17]\n",
            "conditional probability: [1.2243883296794237e-16, 2.1741766357225509e-16]\n",
            "conditional probability: [2.314787478067865e-15, 1.089339018312333e-16]\n",
            "conditional probability: [1.5464046467928435e-12, 2.020985365656804e-11]\n",
            "conditional probability: [8.65986602203992e-11, 7.359755039933532e-10]\n",
            "conditional probability: [1.7491261852563182e-18, 2.630383831497978e-17]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "376sxa2HmeQP",
        "outputId": "be7812a2-310c-44a0-bd9d-4839e3ac032d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "source": [
        "# pred\n",
        "print('pred_body:', pred_body)\n",
        "print('pred_subject:', pred_subject)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_body: [0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "pred_subject: [1 1 0 0 0 0 1 0 1 0 1 1 1]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ekygTKKpR0g",
        "outputId": "a3b94666-365b-4b35-833d-97cfe10a79e7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "source": [
        "# show the result\n",
        "from sklearn import metrics\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = ['Dataset','Precision','Recall','F-score']\n",
        "table.add_row(['email body',\n",
        "               metrics.precision_score(y_test_b, pred_body),\n",
        "               metrics.recall_score(y_test_b, pred_body),\n",
        "               metrics.f1_score(y_test_b, pred_body)])\n",
        "table.add_row(['email subject',\n",
        "               metrics.precision_score(y_test_s, pred_subject),\n",
        "               metrics.recall_score(y_test_s, pred_subject),\n",
        "               metrics.f1_score(y_test_s, pred_subject)])\n",
        "print(table)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+---------------------+--------------------+\n",
            "|    Dataset    |     Precision      |        Recall       |      F-score       |\n",
            "+---------------+--------------------+---------------------+--------------------+\n",
            "|   email body  |        0.5         | 0.16666666666666666 |        0.25        |\n",
            "| email subject | 0.7142857142857143 |  0.8333333333333334 | 0.7692307692307692 |\n",
            "+---------------+--------------------+---------------------+--------------------+\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPOGkE7Apd8M",
        "outputId": "3ce00f09-ad38-4b09-9286-ffacbf316ef3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the results we can find that:**\n",
        "\n",
        "\n",
        "**The email subject dataset can provide better classification with all three measuring scores much more higher.** \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_J_KotFmvDkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **c. Compare your classifier with the scikit-learn implementation(sklearn.naive_bayes.MultinomialNB). Repeat the analysis from (b). (30 points)**"
      ],
      "metadata": {
        "id": "f1DGV99ordqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# data_body\n",
        "clf_b = clf = MultinomialNB()\n",
        "clf_b.fit(X_train_b, y_train_b)\n",
        "pred_b = clf_b.predict(X_test_b)\n",
        "\n",
        "# data_subject\n",
        "clf_s = clf = MultinomialNB()\n",
        "clf_s.fit(X_train_s, y_train_s)\n",
        "pred_s = clf_s.predict(X_test_s)"
      ],
      "outputs": [],
      "metadata": {
        "id": "U_tbEU32rvMm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "source": [
        "# compare the result\n",
        "table2 = PrettyTable()\n",
        "\n",
        "table2.field_names = ['Classifier','Dataset','Precision','Recall','F-score']\n",
        "table2.add_row(['Self-implemented','email body',\n",
        "               metrics.precision_score(y_test_b, pred_body),\n",
        "               metrics.recall_score(y_test_b, pred_body),\n",
        "               metrics.f1_score(y_test_b, pred_body)])\n",
        "table2.add_row(['Self-implemented','email subject',\n",
        "               metrics.precision_score(y_test_s, pred_subject),\n",
        "               metrics.recall_score(y_test_s, pred_subject),\n",
        "               metrics.f1_score(y_test_s, pred_subject)])\n",
        "table2.add_row(['Sklearn','email body',\n",
        "               metrics.precision_score(y_test_b, pred_b),\n",
        "               metrics.recall_score(y_test_b, pred_b),\n",
        "               metrics.f1_score(y_test_b, pred_b)])\n",
        "table2.add_row(['Sklearn','email subject',\n",
        "               metrics.precision_score(y_test_s, pred_s),\n",
        "               metrics.recall_score(y_test_s, pred_s),\n",
        "               metrics.f1_score(y_test_s, pred_s)])\n",
        "print(table2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------------+--------------------+---------------------+--------------------+\n",
            "|    Classifier    |    Dataset    |     Precision      |        Recall       |      F-score       |\n",
            "+------------------+---------------+--------------------+---------------------+--------------------+\n",
            "| Self-implemented |   email body  |        0.5         | 0.16666666666666666 |        0.25        |\n",
            "| Self-implemented | email subject | 0.7142857142857143 |  0.8333333333333334 | 0.7692307692307692 |\n",
            "|     Sklearn      |   email body  |        1.0         |  0.6666666666666666 |        0.8         |\n",
            "|     Sklearn      | email subject | 0.7142857142857143 |  0.8333333333333334 | 0.7692307692307692 |\n",
            "+------------------+---------------+--------------------+---------------------+--------------------+\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG_1SWNqsgge",
        "outputId": "3cec8e61-56e9-4ace-8701-3b240405dbe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the results we can find that:**\n",
        "\n",
        "\n",
        "**For the self-implemented Naive Bayes classification:**\n",
        "\n",
        "**The email subject dataset can provide better classification with all three measuring scores much more higher.** \n",
        "\n",
        "**For the sklearn Naive Bayes classification:**\n",
        "\n",
        "**From the point of view of precision and f-measure measurement, the email body dataset can provide better classification.**  \n",
        "\n",
        "**But from the point of view of recall measurement, the email subject dataset can provide better classification.**"
      ],
      "metadata": {
        "id": "uuOwaEpQ-B27"
      }
    }
  ]
}